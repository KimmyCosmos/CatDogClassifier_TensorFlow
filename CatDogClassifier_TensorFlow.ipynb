{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c86a3f",
   "metadata": {},
   "source": [
    "**Author:** Kimberly Alexander  \n",
    "**Date:** 2024-10-25  \n",
    "**Description:** Cat vs Dog image classification using TensorFlow CNN, demonstrating end-to-end model development, training, evaluation, and saving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06143a2c-975d-4b66-95ac-41f947dcd74c",
   "metadata": {},
   "source": [
    "# Cat vs Dog Image Classification (TensorFlow CNN)\n",
    "This project implements a convolutional neural network (CNN) in TensorFlow to classify images of cats and dogs. It demonstrates data preprocessing with augmentation, model architecture design, training, and evaluation — including accuracy/loss plots and a confusion matrix.\n",
    "\n",
    "## Technologies\n",
    "- Python\n",
    "- TensorFlow\n",
    "- Keras\n",
    "- NumPy\n",
    "- scikit-learn\n",
    "\n",
    "## Key concepts covered\n",
    "- Image preprocessing with data augmentation\n",
    "- CNN architecture for binary classification\n",
    "- Model training and validation\n",
    "- Visualization of accuracy and loss over epochs\n",
    "- Evaluation using a confusion matrix\n",
    "\n",
    "## Imports\n",
    "We import necessary libraries for building, training, evaluating, and visualizing the convolutional neural network (CNN) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6dc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75500180-d64c-4b3d-9e76-f5778904ff2b",
   "metadata": {},
   "source": [
    "For this project, the focus is on binary classification using the classic \"cat and dog\" problem. The goal is to train a model to distinguish between two categories: cats and dogs. A basic overview of the process is as follows:\n",
    "\n",
    "- **Dataset:** The process begins with a labeled dataset containing images of cats and dogs, each labeled with the correct category. This dataset is used for training the model.\n",
    "- **Feature Extraction:** The model analyzes features of the images (e.g., pixel values, textures, shapes, colors) to learn distinguishing characteristics that separate cats from dogs.\n",
    "- **Model Training:** A machine learning algorithm — in this case, a convolutional neural network (CNN) — is trained on the dataset. The algorithm adjusts its parameters to minimize classification error.\n",
    "- **Validation and Testing:** The model is evaluated on a separate set of labeled images (validation and testing datasets) to measure its performance and make adjustments.\n",
    "- **Prediction:** Once trained, the model can categorize new images as either \"cat\" or \"dog\" based on what it has learned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbccd208-6f35-47c5-b0b4-f28916819852",
   "metadata": {},
   "source": [
    "To explore this binary classification task, I used TensorFlow — an open-source machine learning library — to build and train a convolutional neural network (CNN) for classifying images of cats and dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be264600",
   "metadata": {},
   "source": [
    "## Dataset Download and Preparation\n",
    "\n",
    "We download and extract the Cats vs Dogs dataset and define directory paths for training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract the Cats vs Dogs dataset\n",
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "\n",
    "# Define base directories for dataset\n",
    "base_dir = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76454d85",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We use `ImageDataGenerator` to normalize pixel values and apply data augmentation to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Set up data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Ensure alignment for evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28533a1",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "We define a CNN model consisting of convolutional, pooling, and dense layers for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Build CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2409bd6",
   "metadata": {},
   "source": [
    "## Model Compilation and Training\n",
    "\n",
    "We compile the model using the Adam optimizer and binary cross-entropy loss, then train it for 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d68cf1",
   "metadata": {},
   "source": [
    "## Training and Validation Metrics\n",
    "\n",
    "We visualize the training and validation accuracy and loss across epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d249020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss over epochs\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d69f0b",
   "metadata": {},
   "source": [
    "## Saving the Model\n",
    "\n",
    "We save the trained model to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f3a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('cats_and_dogs_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf977062-82c3-4b18-acce-d121a6b7cc57",
   "metadata": {},
   "source": [
    "## Explanation of the Code\n",
    "\n",
    "1. **Data Preparation:** The dataset is automatically downloaded and extracted. It includes separate directories for training and validation sets of cat and dog images.\n",
    "2. **Data Augmentation:** `ImageDataGenerator` is used to apply data augmentation techniques, which help improve model generalization.\n",
    "3. **Model Architecture:** A CNN is built with multiple convolutional and pooling layers, followed by dense layers for binary classification.\n",
    "4. **Training the Model:** The model is compiled using the Adam optimizer and binary cross-entropy loss, and trained for 15 epochs.\n",
    "5. **Saving the Model:** The trained model is saved as an `.h5` file for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46625e4e-9e74-4f1a-973e-28a5814de000",
   "metadata": {},
   "source": [
    "This project demonstrates binary image classification using a convolutional neural network (CNN) to distinguish between cats and dogs. It covers dataset preparation, model training, evaluation (including accuracy/loss plots and a confusion matrix), and saving the trained model for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81e2b9",
   "metadata": {},
   "source": [
    "## Evaluation: Confusion Matrix\n",
    "\n",
    "We compute and display the confusion matrix to visualize how well the model distinguishes cats from dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a21ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the validation data\n",
    "y_pred_prob = model.predict(validation_generator)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Get true labels\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Compute and display the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Cat', 'Dog'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix: Cats vs Dogs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24cf7db",
   "metadata": {},
   "source": [
    "## Evaluation: Classification Report\n",
    "\n",
    "We compute precision, recall, F1-score, and support for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true, y_pred, target_names=['Cat', 'Dog']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec38e2",
   "metadata": {},
   "source": [
    "## Evaluation: Validation Accuracy\n",
    "\n",
    "We compute and display the overall accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Print validation accuracy\n",
    "val_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5676dc75",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Below is a summary of the model's performance, dynamically generated based on the validation results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically generate conclusion text based on actual accuracy\n",
    "print(f\"\"\"\n",
    "The CNN model achieved a validation accuracy of approximately {val_accuracy * 100:.2f}%.\n",
    "The confusion matrix and classification report suggest that the model learned to distinguish between cats and dogs reasonably well.\n",
    "\n",
    "Potential future improvements could include:\n",
    "- Experimenting with deeper architectures or pre-trained models (e.g., transfer learning)\n",
    "- Additional data augmentation or regularization\n",
    "- Hyperparameter tuning\n",
    "\n",
    "This notebook demonstrates the basic workflow of building, training, evaluating, and saving a TensorFlow CNN for image classification.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
